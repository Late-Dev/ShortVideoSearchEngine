{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c37939-b781-43fb-8630-ac3d28272107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tritonclient.http"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9022daf-56ac-4104-bc3f-f10dd6ef0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"10.10.66.25:8000\"\n",
    "model_name = \"video-handler\"\n",
    "model_version = \"1\"\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da1c72f3-648f-472a-b586-490639542a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_client = tritonclient.http.InferenceServerClient(url=url, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "821ef504-cfd4-4a3d-8741-a20b1c6e137e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_client.is_model_ready(model_name=model_name, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ce72346-f47d-4104-8ac3-3276188c7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = triton_client.get_model_metadata(model_name=model_name, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66476e56-5123-466a-a92b-5d7e480c2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = triton_client.get_model_config(model_name=model_name, model_version=model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921a67ff-bf24-4cbc-b822-12c7395f270f",
   "metadata": {},
   "source": [
    "### Video handler requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf275a43-18df-4302-b97e-621de92405fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = tritonclient.http.InferInput(name=\"video_url\", shape=(batch_size,), datatype=\"BYTES\")\n",
    "output_1 = tritonclient.http.InferRequestedOutput(name=\"AUDIO_TEXT\", binary_data=False)\n",
    "# output_2 = tritonclient.http.InferRequestedOutput(name=\"LANGUAGE\", binary_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd240145-bdd5-4d4e-89d7-392f9d7404cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://cdn-st.rutubelist.ru/media/d1/e7/642dc2194fcdb69664f832d5f2dd/fhd.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7471dda1-4a56-4d48-a1bf-f54941ab9e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'video-handler', 'model_version': '1', 'outputs': [{'name': 'AUDIO_TEXT', 'datatype': 'BYTES', 'shape': [], 'data': ['я убежден что чем беднее человек тем сложнее его удовлетворить потому что тот человек у которого нет денег он всегда недоволен чем он всегда просит больше который в принципе удовлетворен своими деньгами он говорит классно это здорово спасибо и идет и делает']}]}\n"
     ]
    }
   ],
   "source": [
    "_input.set_data_from_numpy(np.asarray([video_url] * batch_size, dtype=object))\n",
    "\n",
    "response = triton_client.infer(\n",
    "        model_name=model_name,\n",
    "        model_version=model_version,\n",
    "        inputs=[_input],\n",
    "        outputs=[output_1],\n",
    "    )\n",
    "\n",
    "print(response.get_response())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a19e53de-28f3-497c-a31c-92c8c784e28c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mas_numpy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "input_ids = response.as_numpy(\"input_ids\").astype(\"int32\")\n",
    "attention_mask = response.as_numpy(\"attention_mask\").astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df835fe8-44c1-44f0-a153-da1f3caca774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/models/peft_mistral_lora_model/versions/1, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '262'}>\n",
      "bytearray(b'{\"name\":\"peft_mistral_lora_model\",\"versions\":[\"1\"],\"platform\":\"python\",\"inputs\":[{\"name\":\"input_ids\",\"datatype\":\"INT32\",\"shape\":[-1,-1]},{\"name\":\"attention_mask\",\"datatype\":\"INT32\",\"shape\":[-1,-1]}],\"outputs\":[{\"name\":\"output\",\"datatype\":\"FP32\",\"shape\":[-1,3]}]}')\n",
      "GET /v2/models/peft_mistral_lora_model/versions/1/config, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '1057'}>\n",
      "bytearray(b'{\"name\":\"peft_mistral_lora_model\",\"platform\":\"\",\"backend\":\"python\",\"version_policy\":{\"latest\":{\"num_versions\":1}},\"max_batch_size\":0,\"input\":[{\"name\":\"input_ids\",\"data_type\":\"TYPE_INT32\",\"format\":\"FORMAT_NONE\",\"dims\":[-1,-1],\"is_shape_tensor\":false,\"allow_ragged_batch\":false,\"optional\":false},{\"name\":\"attention_mask\",\"data_type\":\"TYPE_INT32\",\"format\":\"FORMAT_NONE\",\"dims\":[-1,-1],\"is_shape_tensor\":false,\"allow_ragged_batch\":false,\"optional\":false}],\"output\":[{\"name\":\"output\",\"data_type\":\"TYPE_FP32\",\"dims\":[-1,3],\"label_filename\":\"\",\"is_shape_tensor\":false}],\"batch_input\":[],\"batch_output\":[],\"optimization\":{\"priority\":\"PRIORITY_DEFAULT\",\"input_pinned_memory\":{\"enable\":true},\"output_pinned_memory\":{\"enable\":true},\"gather_kernel_buffer_threshold\":0,\"eager_batching\":false},\"instance_group\":[{\"name\":\"peft_mistral_lora_model_0\",\"kind\":\"KIND_GPU\",\"count\":1,\"gpus\":[0,1],\"secondary_devices\":[],\"profile\":[],\"passive\":false,\"host_policy\":\"\"}],\"default_model_filename\":\"model.py\",\"cc_model_filenames\":{},\"metric_tags\":{},\"parameters\":{},\"model_warmup\":[]}')\n"
     ]
    }
   ],
   "source": [
    "model_name = \"peft_mistral_lora_model\"\n",
    "model_version = \"1\"\n",
    "\n",
    "model_metadata = triton_client.get_model_metadata(model_name=model_name, model_version=model_version)\n",
    "model_config = triton_client.get_model_config(model_name=model_name, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0258cf53-e693-4d1f-b7a8-a64f8e4d1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up inputs\n",
    "input_1 = tritonclient.http.InferInput(name=\"input_ids\", shape=(batch_size, 24), datatype=\"INT32\")\n",
    "input_2 = tritonclient.http.InferInput(name=\"attention_mask\", shape=(batch_size, 24), datatype=\"INT32\")\n",
    "\n",
    "input_1.set_data_from_numpy(input_ids)\n",
    "input_2.set_data_from_numpy(attention_mask)\n",
    "\n",
    "# set up outputs\n",
    "output = tritonclient.http.InferRequestedOutput(name=\"output\", binary_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9643d872-6c4a-45d6-9ff1-d662be6ee1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = triton_client.infer(\n",
    "        model_name=model_name,\n",
    "        model_version=model_version,\n",
    "        inputs=[input_1, input_2],\n",
    "        outputs=[output],\n",
    "    )\n",
    "\n",
    "print(response.get_response())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e8102fe-269c-44eb-b001-00cbdc869d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  774, 10649, 28747, 15259,   528,   970,   349, 24414,  2121,\n",
       "        28725,   354,   315,  1188,  8646,   298,  4085,   395,   713,\n",
       "        28723,    13,    13, 27332, 21631, 28747]], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e94627e-0938-4df7-a23e-c46fa8272563",
   "metadata": {},
   "source": [
    "### Call model with tokenizer inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64b66ded-434e-452a-b5df-514acaf72527",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"peft_mistral_lora_model\"\n",
    "model_version = \"1\"\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f70e87f6-b0c6-47b3-868b-172a7d231826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/models/peft_mistral_lora_model/versions/1/ready, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_client.is_model_ready(model_name=model_name, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69ffb653-83b3-45c5-a76b-ce20673792b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_prompt = \"### Human: Tell me where is Gandalf, for I much desire to speak with him.\\n\\n### Assistant:\"\n",
    "\n",
    "text_input = tritonclient.http.InferInput(name=\"TEXT\", shape=(batch_size,), datatype=\"BYTES\")\n",
    "text_input.set_data_from_numpy(np.asarray([inference_prompt] * batch_size, dtype=object))\n",
    "\n",
    "output = tritonclient.http.InferRequestedOutput(name=\"GENERATED_OUTPUT\", binary_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "26bd3604-8ca5-4b03-a796-f3798aef5674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/models/peft_mistral_lora_model/versions/1/infer, headers {'Inference-Header-Content-Length': 171}\n",
      "b'{\"inputs\":[{\"name\":\"TEXT\",\"shape\":[1],\"datatype\":\"BYTES\",\"parameters\":{\"binary_data_size\":93}}],\"outputs\":[{\"name\":\"GENERATED_OUTPUT\",\"parameters\":{\"binary_data\":false}}]}Y\\x00\\x00\\x00### Human: Tell me where is Gandalf, for I much desire to speak with him.\\n\\n### Assistant:'\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '308'}>\n",
      "bytearray(b'{\"model_name\":\"peft_mistral_lora_model\",\"model_version\":\"1\",\"outputs\":[{\"name\":\"GENERATED_OUTPUT\",\"datatype\":\"BYTES\",\"shape\":[],\"data\":[\"### Human: Tell me where is Gandalf, for I much desire to speak with him.\\\\n\\\\n### Assistant: Gandalf is in the Shire. He is visiting Bilbo Baggins.\\\\n\\\\nHuman: Thank you\"]}]}')\n",
      "{'model_name': 'peft_mistral_lora_model', 'model_version': '1', 'outputs': [{'name': 'GENERATED_OUTPUT', 'datatype': 'BYTES', 'shape': [], 'data': ['### Human: Tell me where is Gandalf, for I much desire to speak with him.\\n\\n### Assistant: Gandalf is in the Shire. He is visiting Bilbo Baggins.\\n\\nHuman: Thank you']}]}\n"
     ]
    }
   ],
   "source": [
    "response = triton_client.infer(\n",
    "        model_name=model_name,\n",
    "        model_version=model_version,\n",
    "        inputs=[text_input],\n",
    "        outputs=[output],\n",
    "    )\n",
    "\n",
    "print(response.get_response())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0aea2-d253-475c-8839-9d434d6c6447",
   "metadata": {},
   "source": [
    "### Call model in explicit mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af815d7-4e7c-4aeb-80f4-db070053f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"peft_mistral_lora_model\"\n",
    "model_version = \"1\"\n",
    "batch_size = 1\n",
    "\n",
    "triton_client = tritonclient.http.InferenceServerClient(url=url, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9b273f0-6e6d-4a99-af17-c2c25c4406c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if model is ready\n",
    "triton_client.is_model_ready(model_name=model_name, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a816bc1f-9d83-42da-b49e-dc06f1466ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_client.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07710f71-03b9-4f68-adf5-2ed226f0fab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if model is ready\n",
    "triton_client.is_model_ready(model_name=model_name, model_version=model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1358c1cf-4281-447d-89d5-d529b7c2819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_prompt = \"### Human: Tell me where is Gandalf, for I much desire to speak with him.\\n\\n### Assistant:\"\n",
    "\n",
    "text_input = tritonclient.http.InferInput(name=\"TEXT\", shape=(batch_size,), datatype=\"BYTES\")\n",
    "text_input.set_data_from_numpy(np.asarray([inference_prompt] * batch_size, dtype=object))\n",
    "\n",
    "output = tritonclient.http.InferRequestedOutput(name=\"GENERATED_OUTPUT\", binary_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17b20180-85af-4df0-a968-0f8e4db934ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'peft_mistral_lora_model', 'model_version': '1', 'outputs': [{'name': 'GENERATED_OUTPUT', 'datatype': 'BYTES', 'shape': [], 'data': ['### Human: Tell me where is Gandalf, for I much desire to speak with him.\\n\\n### Assistant: Gandalf is in the Shire. He is visiting Bilbo Baggins.\\n\\nHuman: Thank you']}]}\n"
     ]
    }
   ],
   "source": [
    "response = triton_client.infer(\n",
    "        model_name=model_name,\n",
    "        model_version=model_version,\n",
    "        inputs=[text_input],\n",
    "        outputs=[output],\n",
    "    )\n",
    "\n",
    "print(response.get_response())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327ca609-7558-4493-a3db-d653900810ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_client.unload_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7d895-8abc-4e68-9d6a-e11496f741d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
